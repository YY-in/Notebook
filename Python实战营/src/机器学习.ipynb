{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b129187",
   "metadata": {},
   "source": [
    "\n",
    "机器学习\n",
    "\n",
    "### 1.3.机器学习算法分类\n",
    "\n",
    "| 目标值     | 问题       |\n",
    "| ---------- | ---------- |\n",
    "| 类别       | 分类问题   |\n",
    "| 连续型数据 | 回归问题   |\n",
    "| 没有目标值 | 无监督学习 |\n",
    "\n",
    "### 1.4.机器学习开发流程\n",
    "\n",
    "1. 获取数据\n",
    "2. 数据处理\n",
    "3. 特征工程\n",
    "4. 机器学习算法训练\n",
    "5. 模型评估\n",
    "\n",
    "### 1.5.学习框架和资料介绍\n",
    "\n",
    "明确\n",
    "\n",
    "(1)算法是核心、数据与计算是基础\n",
    "\n",
    "(2)找准定位\n",
    "\n",
    "大部分复杂模型的算法设计都是算法工程师做的,而我们\n",
    "\n",
    "+ 分析数据\n",
    "+ 分析具体业务\n",
    "+ 应用常见算法\n",
    "+ 特征工程、调参数、优化\n",
    "\n",
    "\n",
    "\n",
    "## 2.特征工程\n",
    "\n",
    "### 2.1.数据集\n",
    "\n",
    "#### 2.1.1.可用数据集\n",
    "\n",
    "(1)[skit-learn](http://scikit-learn.org/stable/datasets/index.html#datasets)\n",
    "\n",
    "(2)[kaggle](https://www.kaggle.com/datasets)\n",
    "\n",
    "(3)[UCI](http://archive.ics.uci.edu/ml/)\n",
    "\n",
    "#### 2.1.2. sklearn数据集\n",
    "+ sklearn.datasets\n",
    "  加载获取流行数据集、数据包含在datasets里\n",
    "\n",
    "    + load_*()\n",
    "      获取小规模数据集,数据包含在datasets里\n",
    "      \n",
    "    + datasets.fetch_*(data_home=None)\n",
    "      获取大规模数据集,需要从网络上下载,函数的第一个参数是data_home,表示数据集下载的目录,默认是~/scikit_data/\n",
    "      \n",
    "      \n",
    "1. sklearn.datasets.load_iris()\n",
    "加载并返回莺尾花的数据集\n",
    "|名称|数量|\n",
    "|--|--|\n",
    "|类别|3|\n",
    "|特征|4|\n",
    "|样本数量|150|\n",
    "|每个类别的数量|50|\n",
    "2. sklearn.datasets.load_boston()\n",
    "加载并返回波士顿房价数据集\n",
    "|名称|数量|\n",
    "|--|--|\n",
    "|目标类别|5-50|\n",
    "|特征|13|\n",
    "|样本数量|506\n",
    "3.sklearn 大数据集\n",
    "+ sklearn.datasets.fetch_20newgroups(data_home=None,subset='train')\n",
    "     * subset:'train'或者'test,'all',可选,选择要加载的数据集\n",
    "     * 训练集的\"训练\",测试集的\"\"测试\",两者的\"全部\"\n",
    "##### 2.1.3 sklearn数据集的使用\n",
    "load和fetch返回的数据类型datasets.base.Bunch(继承自字典)\n",
    "dict[\"key\"]=values\n",
    "bunch.key=values\n",
    "键值对描述\n",
    " |键|描述|\n",
    " |:--|:--|\n",
    " |data|特征数据数组,是二位的numpy.ndarray数组|\n",
    " |target|标签数组,是n_samples的一维numpy.ndarray数组|\n",
    " |DESCR|数据描述|\n",
    " |feature_names|特征名,新闻数据,手写数字,回归数据集无序填写|\n",
    " |target_names|标签名|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b92ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "def datasets_demo():\n",
    "    \"\"\"\n",
    "    sklearn数据集的使用\n",
    "    \"\"\"\n",
    "    # 获取数据集\n",
    "    iris = load_iris()\n",
    "    print(\"鸢尾花数据集:\\n\",iris)\n",
    "    print(\"查看数据集描述:\\n\",iris[\"DESCR\"])\n",
    "    print(\"查看特征值的名字:\\n\",iris.feature_names)\n",
    "    print(\"查看特征值:\\n\",iris.data,iris.data.shape)\n",
    "    \n",
    "    # 数据划分\n",
    "    x_train,x_test,y_train,y_test = train_test_split(iris.data,iris.target,test_size=0.2,random_state=22)\n",
    "    print(\"训练集的特征值：\\n\",x_train,x_train.shape)\n",
    "    return None \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 代码1：sklearn数据集使用\n",
    "    datasets_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab55ea0",
   "metadata": {},
   "source": [
    "\n",
    "#### 2.1.4. 数据集的划分\n",
    "机器学习一般的数据集会有分为两个部分：\n",
    "+ 训练数据集：用于训练，**构建模型**\n",
    "+ 通过数据：在模型检验时使用，用于**评估模型是否有效**\n",
    "   测试集20%——30%\n",
    "数据划分 api\n",
    "+ sklearn.model_selection.train_test_split(arrays,*options)\n",
    "    * x数据值特征\n",
    "    * y数据值特征\n",
    "    * test_size测试集的大小，一般为float\n",
    "    * random_state随机数种子,不同的种子会造成不同的随机采样结果.相同的种子采样结果相同\n",
    "    * return训练集特征值,测试集特征值,训练集目标值,测试集目标值\n",
    "\n",
    "\n",
    "### 2.2.特征工程\n",
    "学习目标\n",
    " + 目标\n",
    "    * 了解特征工程在机器学习当中的重要性\n",
    "    * 知道特征工程的分类\n",
    "\n",
    "  特征工程是使用专业背景知识和技巧处理数据，使得特征能在机器学习算法上发挥更好的作用的过程\n",
    "\n",
    "  pandas 数据清洗和数据处理\n",
    "  sklearn 特征工程\n",
    "\n",
    "#### 2.2.1.特征抽取\n",
    "机器学习算法==统计方法==数学公式\n",
    "文本类型==>数值\n",
    "类型==>数值\n",
    "\n",
    "**定义:将任意数据(如文本或图片)转换为可用于机器学习的数字特征**\n",
    "+ 字典特征值提取(特征离散化)\n",
    "+ 文本特征提取\n",
    "+ 图像特征提取(深度学习介绍)\n",
    "\n",
    "**数据提取API**\n",
    "```sklearn.feature_extraction```\n",
    "\n",
    "##### 2.2.1.1 字典特征提取\n",
    "作用:对字典数据进行特征值化(Vectory 数学:向量  物理:矢量)\n",
    "\n",
    "+ ```sklearn.feature_extraction.DictVectorizer(sparse=Ture)```**字典特征提取转换器**- 类别 -> one-hot编码\n",
    "    * ```DictVectorizer.fit_transform(X)```X:字典或者包含字典的迭代器  \n",
    "        返回值:返回sparse矩阵\n",
    "\n",
    "    * ```DictVectorizer.inverse_transform(X)```X:array数组或者sparse矩阵 \n",
    "        返回值:转换之前的数据格式\n",
    "        \n",
    "    * ```DictVectorizer.get_feature_names()```\n",
    "        返回类别名称\n",
    "\n",
    "矩阵 matrix 二维数组\n",
    "向量 vector 一维数组\n",
    "父类：转换器类\n",
    "\n",
    "**应用场景：**\n",
    "+ 数据集中特征类别比较多的情况\n",
    "    1. 将数据集的特征->字典类型\n",
    "    2. DictVectorizer转化\n",
    "+ 本身拿到的数据就是字典类型\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea87d0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_new:\n",
      " [[  0.   1.   0. 100.]\n",
      " [  1.   0.   0.  60.]\n",
      " [  0.   0.   1.  30.]]\n",
      "特征名字:\n",
      " ['city=上海', 'city=北京', 'city=深圳', 'temperature']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "def dict_demo():\n",
    "    \"\"\"\n",
    "    字典特征抽取\n",
    "    \"\"\"\n",
    "    data = [{'city':'北京','temperature':100},{'city':'上海','temperature':60},{'city':'深圳','temperature':30}]\n",
    "    # 1.实例化一个转换器类\n",
    "    transfer=DictVectorizer(sparse=False) # 不填写参数返回稀疏数组\n",
    "\n",
    "    # 2.调用fit_transform()\n",
    "    data_new = transfer.fit_transform(data)\n",
    "\n",
    "    # 打印出的是稀疏矩阵\n",
    "    print(\"data_new:\\n\",data_new)\n",
    "    print(\"特征名字:\\n\",transfer.get_feature_names())\n",
    "    return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dict_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccd180b",
   "metadata": {},
   "source": [
    "\n",
    "##### 2.2.1.2.文本特征提取\n",
    "单词 作为 特征\n",
    "句子、短语、单词、字母\n",
    "特征：特征词\n",
    "\n",
    "+ ``` sklearn.feature_extraction.text.CountVectorizer(stop_words=[])```\n",
    "     返回词频矩阵\n",
    "     stop_words 表示停用词，有的时对我们最终分类没有用的词，将会以列表的形式传递给CountVectorize，这种列表叫做停用词表，许多作自然语言处理的机构就会总结\n",
    "+ ``` CountVectorizer.fit_transform(X)```\n",
    "     X:文本或者包含文本字符串可迭代对象\n",
    "     返回值： 返回sparse矩阵\n",
    "+ ``` CountVectorizer.get_feature_names()```\n",
    "     返回值： 单词列表\n",
    "#### 2.2.2.特征预处理\n",
    "#### 2.2.3.特征降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdf8064",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "def count_demo():\n",
    "    \"\"\"\n",
    "    中文文本特征抽取：CountVectorizer\n",
    "\n",
    "    \"\"\"\n",
    "    data = [\"Life is short,i like like python\",\"life is too long,i dislike python\"]\n",
    "\n",
    "    # 1.实例化一个转换器类\n",
    "    transfer = CountVectorizer( )\n",
    "\n",
    "    # 2.调用fit_transform \n",
    "    data_new = transfer.fit_transform(data)\n",
    "\n",
    "    print(\"data_new:\\n\",data_new.toarray())\n",
    "  \n",
    "\n",
    "    print(\"特征名字：\\n\",transfer.get_feature_names())\n",
    "\n",
    "    return None\n",
    "\n",
    "def count_chinese_demo():\n",
    "    \"\"\"\n",
    "    中文文本特征抽取：CountVectorizer\n",
    "\n",
    "    \"\"\"\n",
    "    data = [\"我 爱 北京 天安 门\",\"天安 门 上太阳 升\"]\n",
    "\n",
    "    # 1.实例化一个转换器类\n",
    "    transfer = CountVectorizer()\n",
    "\n",
    "    # 2.调用fit_transform \n",
    "    data_new = transfer.fit_transform(data)\n",
    "\n",
    "    print(\"data_new:\\n\",data_new.toarray())\n",
    "  \n",
    "    print(\"特征名字：\\n\",transfer.get_feature_names())\n",
    "\n",
    "    return None\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    count_demo()\n",
    "    count_chinese_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25665eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def cut_word(text):\n",
    "    \"\"\"\n",
    "    @description  :proceed chinese sparating words\n",
    "    ---------\n",
    "    \"\"\"\n",
    "    # get generate\n",
    "    generator=jieba.cut(text)\n",
    "    \n",
    "    textlist = list(generator)\n",
    "\n",
    "    # print(textlist)\n",
    "    \n",
    "    #transform to str\n",
    "    string_text=\" \".join(textlist)\n",
    "\n",
    "    # print(string_text)\n",
    "    \n",
    "    # print(type(string_text))\n",
    "    return string_text\n",
    "\n",
    "def count_chinese_demo2():\n",
    "    \"\"\"\n",
    "    @description  : chinese content splite automatically\n",
    "\n",
    "    -------\n",
    "    \"\"\"\n",
    "\n",
    "    data = [\"统计学作为数据分析的入门知识，非常的重要，作为入门，必须要掌握描述性统计以及里面各类图表的应用场景和理解。\",\n",
    "            \"而再深入到，如线性回归，贝叶斯，假设检验等，则是为以后成为高级数据分析师做铺垫，在未来做到建模和预测时。\",\n",
    "            \"会用到很多这类知识，同时在未来进阶过程中，学习机器学习的一些经典算法时，也需要这些知识来帮助理解和学习。\",\n",
    "            \"Excel作为数据分析的基础，是众多数据分析工具的入门工具，而且它的功能非常的强大，具有非常多的实用性，在快速处理一些数据。\",\n",
    "            \"快速出图的时候，非常的灵活，也非常的便捷，其中也有很多的函数，包括max,min,average,find,match,vlookup等。\",\n",
    "            \"可以非常灵活的查询数值或者进行统计分析，同时Excel的数据透视表功能也非常的强大，可以快速的选取所需元素进行分析。\",\n",
    "            \"非常适合用来做快速的数据清洗，入门门槛低，而且实用性非常强。\"]\n",
    "    data_new = []\n",
    "    for sent in data:\n",
    "        data_new.append(cut_word(sent))\n",
    "    # print(data_new)\n",
    "\n",
    "    # 1. instantiate a tranfer obj\n",
    "    transfer = CountVectorizer()\n",
    "\n",
    "    # 2. call the function of fit_transform()\n",
    "    worked_data = transfer.fit_transform(data_new)\n",
    "    print(\"worked_data:\\n\",worked_data.toarray())\n",
    "    print(\"特征名称：\\n\",transfer.get_feature_names())\n",
    "    return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    count_chinese_demo2()\n",
    "    cut_word(\"我爱北京天安门\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ea953c",
   "metadata": {},
   "source": [
    "#### 2.3.5.Tf-idf文本特征提取\n",
    "+ TF-IDF的主要思想是：如果 **某个词或者短语在一篇文章出现的概率高，并且在其他文章很少出现**，则认为该词或者短语具有横好的类别区分能力，适合用来分类。\n",
    "+ TF-IDF作用：用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度\n",
    " \n",
    "> 公式\n",
    "+ 词频（term frequency，tf）指的是某一个给定的词语在该文件中出现的频率\n",
    "+ 逆向文档频率（inverse document frequency，idf）是**一个词语普遍重要性的度量**。某一特定词语的idf，可以由总文件数目初一包含词语之文件的数目，再将得到的商取以10为底的对数得到\n",
    "  \n",
    "$$ TF-IDF = TF*IDF $$\n",
    "\n",
    "> API\n",
    "+ sklearn.feature_extraction.text.TfidfVectorizer(stop_words=None,...)\n",
    "  \n",
    "  返回词的权值矩阵\n",
    "    \n",
    "    * **TfidfVectorizer.fit_transform(X)**  \n",
    "        X:文本或者包含文本字符串的可迭代对象  \n",
    "        返回值：返回sparse矩阵   \n",
    "\n",
    "\n",
    "    * **TfidfVectorizer.inverse_transform(X)**  \n",
    "        X:array数组或者sparse数组  \n",
    "        返回值:转换之前数据格式  \n",
    "\n",
    "\n",
    "    * **TfidfVectorizer.get_feature,name()**\n",
    "        返回:单词列表  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106534d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import jieba\n",
    "def cut_word(text):\n",
    "    return \" \".join(list(jieba.cut(text))) \n",
    "\n",
    "def tfidf_demo():\n",
    "    \"\"\"\n",
    "    @description  : Use TF-IDF to make extraction of text's feature\n",
    "    \"\"\"\n",
    "    data = [\"统计学作为数据分析的入门知识，非常的重要，作为入门，必须要掌握描述性统计以及里面各类图表的应用场景和理解。\",\n",
    "            \"而再深入到，如线性回归，贝叶斯，假设检验等，则是为以后成为高级数据分析师做铺垫，在未来做到建模和预测时。\",\n",
    "            \"会用到很多这类知识，同时在未来进阶过程中，学习机器学习的一些经典算法时，也需要这些知识来帮助理解和学习。\",\n",
    "            \"Excel作为数据分析的基础，是众多数据分析工具的入门工具，而且它的功能非常的强大，具有非常多的实用性，在快速处理一些数据。\",\n",
    "            \"快速出图的时候，非常的灵活，也非常的便捷，其中也有很多的函数，包括max,min,average,find,match,vlookup等。\",\n",
    "            \"可以非常灵活的查询数值或者进行统计分析，同时Excel的数据透视表功能也非常的强大，可以快速的选取所需元素进行分析。\",\n",
    "            \"非常适合用来做快速的数据清洗，入门门槛低，而且实用性非常强。\"]\n",
    "    data_new = []\n",
    "    for sent in data:\n",
    "        data_new.append(cut_word(sent))\n",
    "    # print(data_new)\n",
    "\n",
    "    # 1. instantiate a tranfer obj\n",
    "    transfer= TfidfVectorizer()\n",
    "\n",
    "    # 2. call the function of fit_transform()\n",
    "    worked_data = transfer.fit_transform(data_new)\n",
    "    print(\"worked_data:\\n\",worked_data.toarray())\n",
    "    print(\"特征名称：\\n\",transfer.get_feature_names())\n",
    "    return None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tfidf_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a4b53a",
   "metadata": {},
   "source": [
    "### 2.4.特征预处理\n",
    "#### 2.4.1 什么是特征预处理\n",
    "![特征预处理](../img/特征预处理.png)  \n",
    "通过一些转换函数将特征数据转换成更加适合算法模型的特征数据过程\n",
    "\n",
    "> 包含内容\n",
    " + 数值型数据的无量纲化\n",
    "    + 归一化\n",
    "    + 标椎化\n",
    "  \n",
    "> 特征预处理API  \n",
    " ```python\n",
    " skelearn.proprocessing\n",
    " ```\n",
    " 为什么我们要进行归化和标准化?  \n",
    "\n",
    " + 特征值的单位或者大小,或者某特征的方差相比其他的特征要大出几个数量级,容易影响(支配)目标结果,使得一些算法无法学习到其他的特征\n",
    "  \n",
    "![归一化和标准化](..\\img\\归一化.png)\n",
    "\n",
    "#### 2.4.2.归一化\n",
    "> 定义  \n",
    "\n",
    "通过对原始数据进行变换把数据映射到(默认[0,1])之间\n",
    "\n",
    "> 公式\n",
    "\n",
    "![归一化公式](..\\img\\归一化公式.png)\n",
    "\n",
    "> API  \n",
    "\n",
    "* ```sklearn.preprocessing.MinMaxScaler(feature_range=(0,1)...)```\n",
    "  +   ```MinMaxScalar.fit_transform(X)```   \n",
    "        X: numpy array 格式的数据[n_samples,n_features]   \n",
    "        返回值:转换后的形状相同的array\n",
    "\n",
    "> 总结\n",
    "\n",
    "注意最大值和最小值是变化的.另外,最大值与最小值非常容易收到异常点影响,\n",
    "**所以这种发发鲁棒性较差(稳定性),只适合传统精确小数据场合**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744f6712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def minmax_demo():\n",
    "    \n",
    "    \"\"\"\n",
    "    @description  : MInMaxScaler test\n",
    "    ---------\n",
    "    \"\"\"\n",
    "    # 1.get data\n",
    "    data = pd.read_csv(\"..\\lib\\dating.txt\").iloc[:,:3]\n",
    "\n",
    "    print(\"data\\n:\",data)\n",
    "\n",
    "    # 2.instantiate a transfer class\n",
    "    transfer = MinMaxScaler()\n",
    "\n",
    "    # 3.call the fit_transform()  function to make transform\n",
    "    data_new = transfer.fit_transform(data)\n",
    "    print(\"data_new：\\n\",data_new)\n",
    "    return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    minmax_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca99285f",
   "metadata": {},
   "source": [
    "#### 2.4.3.标准化\n",
    "> 定义  \n",
    "\n",
    " 通过对原始数据进行变换把数据映射到(默认[0,1])之间\n",
    "\n",
    "> 公式  \n",
    "\n",
    "![标准化公式](..\\img\\标准化的公式.png)\n",
    " \n",
    "当出现异常值.可以进行这样的无量纲化的处理\n",
    "\n",
    "![标准化的异常值](..\\img\\标准化的异常值.png)\n",
    "\n",
    "+ 对于**归一化**来说:如果出现异常点,影响了最大值和最小值,那么结果显然会发生变化\n",
    "+ 对于**标准化**来说:如果出现了异常点,由于具有一定数量级,少量的异常点对于平均值的影响不大,从而方差改变极小\n",
    "\n",
    "> 代码\n",
    "\n",
    "+ ```sklearn.preprocessing.StandardScaler()```\n",
    "\n",
    "处理之后,对每列来说,所有数据都聚集在均值0附近,标准差为1\n",
    "\n",
    "+ ```StandardScaler.fit_transform(X)```\n",
    "  + X : numpy array 格式数据[n_samples,n_features]  \n",
    "  + 返回值：转换后的形状相同的array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2927f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def stand_demo():\n",
    "    \"\"\"\n",
    "    标准化\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 1、获取数据\n",
    "    data = pd.read_csv(\"..\\lib\\dating.txt\")\n",
    "    data = data.iloc[:, :3]\n",
    "    print(\"data:\\n\", data)\n",
    "\n",
    "    # 2、实例化一个转换器类\n",
    "    transfer = StandardScaler()\n",
    "\n",
    "    # 3、调用fit_transform\n",
    "    data_new = transfer.fit_transform(data)\n",
    "    print(\"data_new:\\n\", data_new)\n",
    "    return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    stand_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb8eec1",
   "metadata": {},
   "source": [
    "### 2.5.特征降维\n",
    "#### 2.5.1.特征降维简述\n",
    "> 定义\n",
    "\n",
    "特征降维是指在某些限定条件下，降低随机变量(特征)个数，得到一组“不相关”主变量的过程\n",
    "\n",
    "目的:要求特征与特征之间**不相关**,降低的对象是二维数组\n",
    "\n",
    "![特征降维](..\\img\\特征降维.png)\n",
    "\n",
    "+ 相关特征(correlated feature)\n",
    "    + 相对湿度与降雨量\n",
    "    + 等等\n",
    "  \n",
    "正是因为在进行训练的时候,我们都是使用特征进行学习，如果特征本身存在问题或者特征之间相关性较强，对于算法学习预测会影响较大\n",
    "\n",
    "> 方式\n",
    "1. 特征选择\n",
    "2. 主成分分析(可以理解一种特征提取的方式)\n",
    "\n",
    "#### 2.5.2.特征选择\n",
    " \n",
    "> 定义\n",
    "\n",
    " 数据中包含**冗余或相关变量（或者称特征、属性、指标等）**,旨在从原有的特征中找出主要特征\n",
    " \n",
    "> 分类\n",
    "1. Filter 过滤式\n",
    "    方差选择法：低方差特征过滤\n",
    "    相关系数：特征与特征之间相关程度\n",
    "2. Embeded 嵌入式\n",
    "   决策树 day2\n",
    "   正则化 day3\n",
    "   深度学习 day5\n",
    "\n",
    "#### 2.5.3. 过滤式\n",
    "##### 2.5.3.1 低方差特征过滤\n",
    "> 定义\n",
    " \n",
    " 删除低方差的一些特征,前面讲过方差的意义,再结合方差的大小来考虑这个方式的角度.\n",
    "\n",
    " + 特征方差小:某个特征与大多样本的值比较接近\n",
    " + 特征方差大:某个特征和大多样本的值有差别\n",
    "\n",
    "> API\n",
    "\n",
    "![低方差过滤波器](..\\img\\低方差过滤器API.png)\n",
    "\n",
    "##### 2.5.3.2.相关系数\n",
    "+ 皮尔逊相关系数(Pearson Correlation Coefficient)  \n",
    "   反应变量之间相关关系密切程度的统计指标,取值范围(-1~1)\n",
    "\n",
    "> 计算公式实例(了解)\n",
    "\n",
    "![皮尔曼相关系数示例](..\\img\\皮尔曼相关系数示例.png)\n",
    "![皮尔曼示例](..\\img\\皮尔曼示例.png)\n",
    "\n",
    "> 特点\n",
    "\n",
    "![皮尔曼系数特点](..\\img\\皮尔曼系数特点.png)\n",
    "\n",
    "> API\n",
    "+ ```from scipy.stats import pearsonr```\n",
    "    + x:(N.) array_like\n",
    "    + y:(N.) array_like Return (Pearson's correlation coefficient,p-value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20a6da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def variance_demo():\n",
    "    \"\"\"\n",
    "    过滤低方差特征\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 1、获取数据\n",
    "    data = pd.read_csv(\"../lib/factor_returns.csv\")\n",
    "    data = data.iloc[:, 1:-2]\n",
    "    print(\"data:\\n\", data)\n",
    "\n",
    "    # 2、实例化一个转换器类\n",
    "    transfer = VarianceThreshold(threshold=10)\n",
    "\n",
    "    # 3、调用fit_transform\n",
    "    data_new = transfer.fit_transform(data)\n",
    "    print(\"data_new:\\n\", data_new, data_new.shape)\n",
    "\n",
    "    # 计算某两个变量之间的相关系数\n",
    "    r1 = pearsonr(data[\"pe_ratio\"], data[\"pb_ratio\"])\n",
    "    print(\"相关系数：\\n\", r1)\n",
    "    r2 = pearsonr(data['revenue'], data['total_expense'])\n",
    "    print(\"revenue与total_expense之间的相关性：\\n\", r2)\n",
    "\n",
    "\n",
    "    return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    variance_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14883908",
   "metadata": {},
   "source": [
    "#### 2.6.1.主成分分析（PCA）\n",
    "> 定义\n",
    "\n",
    " 高维数据转化为低维数据的过程,在此过程中**可能会舍弃原有数据、创造新的变量**\n",
    "\n",
    "> 作用\n",
    "\n",
    "**是数据维数压缩,尽可能降低原数据的维数(复杂度),损失少量信息.**\n",
    "\n",
    "> 应用\n",
    "\n",
    "回归分析或者聚类分析当中\n",
    "\n",
    "> API\n",
    "\n",
    "![PCAAPI](../img/PCAAPI.png))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78575452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_new:\n",
      " [[-3.13587302e-16  3.82970843e+00]\n",
      " [-5.74456265e+00 -1.91485422e+00]\n",
      " [ 5.74456265e+00 -1.91485422e+00]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def pca_demo():\n",
    "    \"\"\"\n",
    "    PCA降维\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    data = [[2,8,4,5], [6,3,0,8], [5,4,9,1]]\n",
    "\n",
    "    # 1、实例化一个转换器类\n",
    "    transfer = PCA(n_components=0.95)\n",
    "\n",
    "    # 2、调用fit_transform\n",
    "    data_new = transfer.fit_transform(data)\n",
    "    print(\"data_new:\\n\", data_new)\n",
    "    return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pca_demo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
