{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b129187",
   "metadata": {},
   "source": [
    "机器学习\n",
    "\n",
    "### 1.3.机器学习算法分类\n",
    "\n",
    "| 目标值     | 问题       |\n",
    "| ---------- | ---------- |\n",
    "| 类别       | 分类问题   |\n",
    "| 连续型数据 | 回归问题   |\n",
    "| 没有目标值 | 无监督学习 |\n",
    "\n",
    "### 1.4.机器学习开发流程\n",
    "\n",
    "1. 获取数据\n",
    "2. 数据处理\n",
    "3. 特征工程\n",
    "4. 机器学习算法训练\n",
    "5. 模型评估\n",
    "\n",
    "### 1.5.学习框架和资料介绍\n",
    "\n",
    "明确\n",
    "\n",
    "(1)算法是核心、数据与计算是基础\n",
    "\n",
    "(2)找准定位\n",
    "\n",
    "大部分复杂模型的算法设计都是算法工程师做的,而我们\n",
    "\n",
    "+ 分析数据\n",
    "+ 分析具体业务\n",
    "+ 应用常见算法\n",
    "+ 特征工程、调参数、优化\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 2.特征工程\n",
    "\n",
    "### 2.1.数据集\n",
    "\n",
    "#### 2.1.1.可用数据集\n",
    "\n",
    "(1)[skit-learn](http://scikit-learn.org/stable/datasets/index.html#datasets)\n",
    "\n",
    "(2)[kaggle](https://www.kaggle.com/datasets)\n",
    "\n",
    "(3)[UCI](http://archive.ics.uci.edu/ml/)\n",
    "\n",
    "#### 2.1.2. sklearn数据集\n",
    "+ sklearn.datasets\n",
    "  加载获取流行数据集、数据包含在datasets里\n",
    "\n",
    "    + load_*()\n",
    "      获取小规模数据集,数据包含在datasets里\n",
    "      \n",
    "    + datasets.fetch_*(data_home=None)\n",
    "      获取大规模数据集,需要从网络上下载,函数的第一个参数是data_home,表示数据集下载的目录,默认是~/scikit_data/\n",
    "      \n",
    "      \n",
    "1. sklearn.datasets.load_iris()\n",
    "加载并返回莺尾花的数据集\n",
    "|名称|数量|\n",
    "|--|--|\n",
    "|类别|3|\n",
    "|特征|4|\n",
    "|样本数量|150|\n",
    "|每个类别的数量|50|\n",
    "2. sklearn.datasets.load_boston()\n",
    "加载并返回波士顿房价数据集\n",
    "|名称|数量|\n",
    "|--|--|\n",
    "|目标类别|5-50|\n",
    "|特征|13|\n",
    "|样本数量|506\n",
    "3.sklearn 大数据集\n",
    "+ sklearn.datasets.fetch_20newgroups(data_home=None,subset='train')\n",
    "     * subset:'train'或者'test,'all',可选,选择要加载的数据集\n",
    "     * 训练集的\"训练\",测试集的\"\"测试\",两者的\"全部\"\n",
    "##### 2.1.3 sklearn数据集的使用\n",
    "load和fetch返回的数据类型datasets.base.Bunch(继承自字典)\n",
    "dict[\"key\"]=values\n",
    "bunch.key=values\n",
    "键值对描述\n",
    " |键|描述|\n",
    " |:--|:--|\n",
    " |data|特征数据数组,是二位的numpy.ndarray数组|\n",
    " |target|标签数组,是n_samples的一维numpy.ndarray数组|\n",
    " |DESCR|数据描述|\n",
    " |feature_names|特征名,新闻数据,手写数字,回归数据集无序填写|\n",
    " |target_names|标签名|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b92ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "def datasets_demo():\n",
    "    \"\"\"\n",
    "    sklearn数据集的使用\n",
    "    \"\"\"\n",
    "    # 获取数据集\n",
    "    iris = load_iris()\n",
    "    print(\"鸢尾花数据集:\\n\",iris)\n",
    "    print(\"查看数据集描述:\\n\",iris[\"DESCR\"])\n",
    "    print(\"查看特征值的名字:\\n\",iris.feature_names)\n",
    "    print(\"查看特征值:\\n\",iris.data,iris.data.shape)\n",
    "    \n",
    "    # 数据划分\n",
    "    x_train,x_test,y_train,y_test = train_test_split(iris.data,iris.target,test_size=0.2,random_state=22)\n",
    "    print(\"训练集的特征值：\\n\",x_train,x_train.shape)\n",
    "    return None \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 代码1：sklearn数据集使用\n",
    "    datasets_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab55ea0",
   "metadata": {},
   "source": [
    "#### 2.1.4. 数据集的划分\n",
    "机器学习一般的数据集会有分为两个部分：\n",
    "+ 训练数据集：用于训练，**构建模型**\n",
    "+ 通过数据：在模型检验时使用，用于**评估模型是否有效**\n",
    "   测试集20%——30%\n",
    "数据划分 api\n",
    "+ sklearn.model_selection.train_test_split(arrays,*options)\n",
    "    * x数据值特征\n",
    "    * y数据值特征\n",
    "    * test_size测试集的大小，一般为float\n",
    "    * random_state随机数种子,不同的种子会造成不同的随机采样结果.相同的种子采样结果相同\n",
    "    * return训练集特征值,测试集特征值,训练集目标值,测试集目标值\n",
    "\n",
    "\n",
    "### 2.2.特征工程\n",
    "学习目标\n",
    " + 目标\n",
    "    * 了解特征工程在机器学习当中的重要性\n",
    "    * 知道特征工程的分类\n",
    "\n",
    "  特征工程是使用专业背景知识和技巧处理数据，使得特征能在机器学习算法上发挥更好的作用的过程\n",
    "\n",
    "  pandas 数据清洗和数据处理\n",
    "  sklearn 特征工程\n",
    "\n",
    "#### 2.2.1.特征抽取\n",
    "机器学习算法==统计方法==数学公式\n",
    "文本类型==>数值\n",
    "类型==>数值\n",
    "\n",
    "**定义:将任意数据(如文本或图片)转换为可用于机器学习的数字特征**\n",
    "+ 字典特征值提取(特征离散化)\n",
    "+ 文本特征提取\n",
    "+ 图像特征提取(深度学习介绍)\n",
    "\n",
    "**数据提取API**\n",
    "```sklearn.feature_extraction```\n",
    "\n",
    "##### 2.2.1.1 字典特征提取\n",
    "作用:对字典数据进行特征值化(Vectory 数学:向量  物理:矢量)\n",
    "\n",
    "+ ```sklearn.feature_extraction.DictVectorizer(sparse=Ture)```**字典特征提取转换器**- 类别 -> one-hot编码\n",
    "    * ```DictVectorizer.fit_transform(X)```X:字典或者包含字典的迭代器  \n",
    "        返回值:返回sparse矩阵\n",
    "\n",
    "    * ```DictVectorizer.inverse_transform(X)```X:array数组或者sparse矩阵 \n",
    "        返回值:转换之前的数据格式\n",
    "        \n",
    "    * ```DictVectorizer.get_feature_names()```\n",
    "        返回类别名称\n",
    "\n",
    "矩阵 matrix 二维数组\n",
    "向量 vector 一维数组\n",
    "父类：转换器类\n",
    "\n",
    "**应用场景：**\n",
    "+ 数据集中特征类别比较多的情况\n",
    "    1. 将数据集的特征->字典类型\n",
    "    2. DictVectorizer转化\n",
    "+ 本身拿到的数据就是字典类型\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea87d0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_new:\n",
      " [[  0.   1.   0. 100.]\n",
      " [  1.   0.   0.  60.]\n",
      " [  0.   0.   1.  30.]]\n",
      "特征名字:\n",
      " ['city=上海', 'city=北京', 'city=深圳', 'temperature']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "def dict_demo():\n",
    "    \"\"\"\n",
    "    字典特征抽取\n",
    "    \"\"\"\n",
    "    data = [{'city':'北京','temperature':100},{'city':'上海','temperature':60},{'city':'深圳','temperature':30}]\n",
    "    # 1.实例化一个转换器类\n",
    "    transfer=DictVectorizer(sparse=False) # 不填写参数返回稀疏数组\n",
    "\n",
    "    # 2.调用fit_transform()\n",
    "    data_new = transfer.fit_transform(data)\n",
    "\n",
    "    # 打印出的是稀疏矩阵\n",
    "    print(\"data_new:\\n\",data_new)\n",
    "    print(\"特征名字:\\n\",transfer.get_feature_names())\n",
    "    return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dict_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccd180b",
   "metadata": {},
   "source": [
    "\n",
    "##### 2.2.1.2.文本特征提取\n",
    "单词 作为 特征\n",
    "句子、短语、单词、字母\n",
    "特征：特征词\n",
    "\n",
    "+ ``` sklearn.feature_extraction.text.CountVectorizer(stop_words=[])```\n",
    "     返回词频矩阵\n",
    "     stop_words 表示停用词，有的时对我们最终分类没有用的词，将会以列表的形式传递给CountVectorize，这种列表叫做停用词表，许多作自然语言处理的机构就会总结\n",
    "+ ``` CountVectorizer.fit_transform(X)```\n",
    "     X:文本或者包含文本字符串可迭代对象\n",
    "     返回值： 返回sparse矩阵\n",
    "+ ``` CountVectorizer.get_feature_names()```\n",
    "     返回值： 单词列表\n",
    "#### 2.2.2.特征预处理\n",
    "#### 2.2.3.特征降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cdf8064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_new:\n",
      " [[0 1 1 2 0 1 1 0]\n",
      " [1 1 1 0 1 1 0 1]]\n",
      "特征名字：\n",
      " ['dislike', 'is', 'life', 'like', 'long', 'python', 'short', 'too']\n",
      "data_new:\n",
      " [[0 1 1]\n",
      " [1 0 1]]\n",
      "特征名字：\n",
      " ['上太阳', '北京', '天安']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "def count_demo():\n",
    "    \"\"\"\n",
    "    中文文本特征抽取：CountVectorizer\n",
    "\n",
    "    \"\"\"\n",
    "    data = [\"Life is short,i like like python\",\"life is too long,i dislike python\"]\n",
    "\n",
    "    # 1.实例化一个转换器类\n",
    "    transfer = CountVectorizer( )\n",
    "\n",
    "    # 2.调用fit_transform \n",
    "    data_new = transfer.fit_transform(data)\n",
    "\n",
    "    print(\"data_new:\\n\",data_new.toarray())\n",
    "  \n",
    "\n",
    "    print(\"特征名字：\\n\",transfer.get_feature_names())\n",
    "\n",
    "    return None\n",
    "\n",
    "def count_chinese_demo():\n",
    "    \"\"\"\n",
    "    中文文本特征抽取：CountVectorizer\n",
    "\n",
    "    \"\"\"\n",
    "    data = [\"我 爱 北京 天安 门\",\"天安 门 上太阳 升\"]\n",
    "\n",
    "    # 1.实例化一个转换器类\n",
    "    transfer = CountVectorizer()\n",
    "\n",
    "    # 2.调用fit_transform \n",
    "    data_new = transfer.fit_transform(data)\n",
    "\n",
    "    print(\"data_new:\\n\",data_new.toarray())\n",
    "  \n",
    "    print(\"特征名字：\\n\",transfer.get_feature_names())\n",
    "\n",
    "    return None\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    count_demo()\n",
    "    count_chinese_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25665eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worked_data:\n",
      " [[0 0 0 0 0 0 0 0 1 0 0 2 0 0 0 0 2 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0\n",
      "  0 1 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0\n",
      "  0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      "  0 0 0 0 0 1 0 0 0 0 0 1 1]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 3 0 0\n",
      "  1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 2 1 0 1 0 0 0 0 0 1 1 0\n",
      "  1 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 2\n",
      "  0 0 0 1 0 0 1 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
      " [1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 2 0 1 0 0 0 0 0 0 0 0\n",
      "  0 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 2\n",
      "  0 1 1 0 0 0 0 0 1 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      "  0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      "  0 0 0 0 0 0 1 0 1 0 1 0 0]]\n",
      "特征名称：\n",
      " ['average', 'excel', 'find', 'match', 'max', 'min', 'vlookup', '一些', '以及', '以后', '众多', '作为', '便捷', '假设检验', '做到', '元素', '入门', '其中', '具有', '出图', '函数', '分析', '分析师', '功能', '包括', '可以', '各类', '同时', '回归', '图表', '场景', '基础', '处理', '学习', '实用性', '工具', '帮助', '应用', '建模', '强大', '很多', '必须', '快速', '成为', '或者', '掌握', '描述性', '数值', '数据', '数据分析', '时候', '未来', '机器', '查询', '深入', '清洗', '灵活', '理解', '用到', '用来', '知识', '算法', '线性', '经典', '统计', '统计分析', '统计学', '而且', '贝叶斯', '过程', '这些', '进行', '进阶', '选取', '透视', '里面', '重要', '铺垫', '门槛', '需要', '非常', '非常灵活', '非常适合', '预测', '高级']\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def cut_word(text):\n",
    "    \"\"\"\n",
    "    @description  :proceed chinese sparating words\n",
    "    ---------\n",
    "    @param  : text     \n",
    "    -------\n",
    "    @Returns  :text\n",
    "    -------\n",
    "    \"\"\"\n",
    "    # get generate\n",
    "    generator=jieba.cut(text)\n",
    "    \n",
    "    textlist = list(generator)\n",
    "\n",
    "    # print(textlist)\n",
    "    \n",
    "    #transform to str\n",
    "    string_text=\" \".join(textlist)\n",
    "\n",
    "    # print(string_text)\n",
    "    \n",
    "    # print(type(string_text))\n",
    "    return string_text\n",
    "\n",
    "def count_chinese_demo2():\n",
    "    \"\"\"\n",
    "    @description  : chinese content splite automatically\n",
    "    ---------\n",
    "    @param  :\n",
    "    -------\n",
    "    @Returns  :\n",
    "    -------\n",
    "    \"\"\"\n",
    "\n",
    "    data = [\"统计学作为数据分析的入门知识，非常的重要，作为入门，必须要掌握描述性统计以及里面各类图表的应用场景和理解。\",\n",
    "            \"而再深入到，如线性回归，贝叶斯，假设检验等，则是为以后成为高级数据分析师做铺垫，在未来做到建模和预测时。\",\n",
    "            \"会用到很多这类知识，同时在未来进阶过程中，学习机器学习的一些经典算法时，也需要这些知识来帮助理解和学习。\",\n",
    "            \"Excel作为数据分析的基础，是众多数据分析工具的入门工具，而且它的功能非常的强大，具有非常多的实用性，在快速处理一些数据。\",\n",
    "            \"快速出图的时候，非常的灵活，也非常的便捷，其中也有很多的函数，包括max,min,average,find,match,vlookup等。\",\n",
    "            \"可以非常灵活的查询数值或者进行统计分析，同时Excel的数据透视表功能也非常的强大，可以快速的选取所需元素进行分析。\",\n",
    "            \"非常适合用来做快速的数据清洗，入门门槛低，而且实用性非常强。\"]\n",
    "    data_new = []\n",
    "    for sent in data:\n",
    "        data_new.append(cut_word(sent))\n",
    "    # print(data_new)\n",
    "\n",
    "    # 1. instantiate a tranfer obj\n",
    "    transfer = CountVectorizer()\n",
    "\n",
    "    # 2. call the function of fit_transform()\n",
    "    worked_data = transfer.fit_transform(data_new)\n",
    "    print(\"worked_data:\\n\",worked_data.toarray())\n",
    "    print(\"特征名称：\\n\",transfer.get_feature_names())\n",
    "    return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    count_chinese_demo2()\n",
    "    cut_word(\"我爱北京天安门\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
